#!/bin/bash
while [ $# -gt 0 ]; do
    if [[ $1 == "--"* ]]; then
        v="${1/--/}"
        declare "$v"="$2"
        shift
    fi
    shift
done


EXTENSION=".csv"
DELIMITER=","

DEVICE="cuda"
BATCH_SIZE=1024

MAXSIZE=2000000

# Get file size
echo Getting file size of $input_file
FILESIZE=$(du $input_file | awk '{print $1}')
# Checkpoint
echo "Size of $input_file = $FILESIZE KB."

if [ "$index_type" = "auto" ] ||  [ "$index_type" = "" ]; then

    if (( FILESIZE > MAXSIZE)); then
        INDEX_TYPE="clustered"
    else
        INDEX_TYPE="in_memory"
    fi

else
INDEX_TYPE=$index_type

fi

# Specify GPU device
if [ "$gpu_device" = "" ]; then
    GPU_DEVICE="0"

else
GPU_DEVICE=$gpu_device
fi

# Specify destination folder
if [ "$dest" = "" ]; then
    OUTPUT_DIRECTORY="/data/output"
else
    OUTPUT_DIRECTORY=$dest

fi



CHUNK_SIZE=100000  # Chunk size for embeddings computation

echo "Running CHEESE inference..."
echo "Saving outputs to $OUTPUT_DIRECTORY"
echo "Making output directory $OUTPUT_DIRECTORY"
mkdir $OUTPUT_DIRECTORY
sudo docker run -u root -v /data:/data -it --env CHEESE_LICENSE_FILE=$LICENSE_FILE --env LICENSING=$LICENSING --gpus all --rm $INFERENCE_IMAGE --index_type $INDEX_TYPE --input_file $input_file --extension $EXTENSION --delimiter $DELIMITER --output_directory $OUTPUT_DIRECTORY --gpu_device_id $GPU_DEVICE --batch_size $BATCH_SIZE --chunk_size $CHUNK_SIZE --validate_smiles $valid_smiles --canonicalize_smiles $canonical_smiles
