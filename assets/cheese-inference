#!/bin/bash
while [ $# -gt 0 ]; do
    if [[ $1 == "--"* ]]; then
        v="${1/--/}"
        declare "$v"="$2"
        shift
    fi
    shift
done


update-cheese

EXTENSION=".csv"
DELIMITER=","

DEVICE="cuda"
BATCH_SIZE=128

OUTPUT_DIRECTORY="/data/output"

INPUT_FILE="/data/"$input_file

MAXSIZE=2000

# Get file size
echo Getting file size of $INPUT_FILE
FILESIZE=$(du $INPUT_FILE | awk '{print $1}')
# Checkpoint
echo "Size of $INPUT_FILE = $FILESIZE KB."

if (( $index_type == "")); then

    if (( FILESIZE > MAXSIZE)); then
        INDEX_TYPE="clustered"
    else
        INDEX_TYPE="in_memory"
    fi

else
INDEX_TYPE=$index_type

fi

# Specify GPU device
if (( $gpu_device == "")); then
    GPU_DEVICE="0"

else
GPU_DEVICE=$gpu_device
fi

# Specify SMILES validation
if (( $canonicalize_smiles == "")); then
    CANONICAL_SMI="true"

else
CANONICAL_SMI=$canonicalize_smiles
fi

# Specify SMILES canonicalization
if (( $validate_smiles == "")); then
    VALIDATE_SMI="true"

else
VALIDATE_SMI=$validate_smiles
fi


CHUNK_SIZE=100000  # Chunk size for embeddings computation

echo "Running CHEESE inference..."
echo "Making output directory"
mkdir $OUTPUT_DIRECTORY
sudo docker run -u root -v /data:/data -it CHEESE_LICENSE_FILE=$LICENSE_FILE --env LICENSING=$LICENSING --gpus all --rm $INFERENCE_IMAGE --index_type $INDEX_TYPE --input_file $INPUT_FILE --extension $EXTENSION --delimiter $DELIMITER --output_directory $OUTPUT_DIRECTORY --gpu_device_id $GPU_DEVICE --batch_size $BATCH_SIZE --chunk_size $CHUNK_SIZE --validate_smiles $VALIDATE_SMI --canonicalize_smiles $CANONICAL_SMI
