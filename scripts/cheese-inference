#!/bin/bash
while [ $# -gt 0 ]; do
    if [[ $1 == "--"* ]]; then
        v="${1/--/}"
        declare "$v"="$2"
        shift
    fi
    shift
done


EXTENSION=".csv"
DELIMITER=","

DEVICE="cuda"
BATCH_SIZE=1024

MAXSIZE=1000000

INPUT_FILE=$input_file
DEST_INPUT_FILE="/data/"$input_file

# Get file size
echo Getting file size of $INPUT_FILE
FILESIZE=$(du $INPUT_FILE | awk '{print $1}')
# Checkpoint
echo "Size of $INPUT_FILE = $FILESIZE KB."

if [ "$index_type" = "auto" ] ||  [ "$index_type" = "" ]; then

    if (( FILESIZE > MAXSIZE)); then
        INDEX_TYPE="clustered"
    else
        INDEX_TYPE="in_memory"
    fi

else
INDEX_TYPE=$index_type

fi



CHUNK_SIZE=100000  # Chunk size for embeddings computation

echo "Running CHEESE inference..."
OUTPUT_DIRECTORY="/data/${dest}"
NEW_OUTPUT_DIRECTORY="${dest}"
echo Saving outputs to $NEW_OUTPUT_DIRECTORY
mkdir $NEW_OUTPUT_DIRECTORY
docker run -u $UID -v /:/data -it --env CUPY_CACHE_DIR=/tmp --env NCCL_SHM_DISABLE=1 --env CHEESE_LICENSE_FILE=/data/$LICENSE_FILE --env LICENSING=True --gpus all --rm $INFERENCE_IMAGE --index_type $INDEX_TYPE --input_file $DEST_INPUT_FILE --extension $EXTENSION --delimiter $DELIMITER --output_directory $OUTPUT_DIRECTORY --gpu_device_ids $gpu_devices --batch_size $BATCH_SIZE --chunk_size $CHUNK_SIZE --validate_smiles $valid_smiles --canonicalize_smiles $canonical_smiles
